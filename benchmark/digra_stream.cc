/**
 * @file digra_stream.cc
 * @brief DIGRA baseline incremental streaming benchmark using project's IO and groundtruth.
 *
 * This driver aligns DIGRA's IO with our project's DataWrapper pipeline:
 * - Reads datasets and queries via DataWrapper (same as our methods).
 * - Uses the same groundtruth CSV files generated by our pipeline.
 * - Maintains the same search-ef sweep and logging format as incremental_stream.cc.
 * - Maps DIGRA's key/value to our positional IDs (key = id, value = id) so ranges [l,r]
 *   are consistent with our positional-range groundtruth.
 *
 * C++ standard: C++17
 */

#include <algorithm>
#include <iostream>
#include <map>
#include <numeric>
#include <random>
#include <sstream>
#include <vector>
#include <tuple>
#include <iomanip>
#include <sys/stat.h>
#include <fstream>
#include <cstring>
#include <chrono>

#include "data_wrapper.h"
#include "utils.h"

#include "../DIGRA/TreeHNSW.hpp"

using std::cout;
using std::endl;
using std::string;
using std::to_string;
using std::vector;

// Function to replace a substring in a single path
static void ReplaceSubstringInPath(std::string &path, const std::string &old_str, const std::string &new_str) {
    size_t pos = path.find(old_str);
    if (pos != std::string::npos) {
        path.replace(pos, old_str.length(), new_str);
    }
}

// Function to replace a substring in a vector of paths
static void ReplaceSubstringInPaths(std::vector<std::string> &paths, const std::string &old_str, const std::string &new_str) {
    for (std::string &path : paths) {
        size_t pos = path.find(old_str);
        if (pos != std::string::npos) {
            path.replace(pos, old_str.length(), new_str);
        }
    }
}

// Append run parameters to filenames (to mirror incremental_stream.cc convention)
static void tagParameters(vector<string> &paths, string file_type,  unsigned index_k, unsigned ef_max, unsigned ef_construction) {
    string suffix = "_" + to_string(index_k) + "_" + to_string(ef_max) + "_" + to_string(ef_construction);
    for (auto &path : paths) {
        size_t pos = path.find(file_type);
        if (pos != string::npos) {
            path.insert(pos, suffix);
        }
    }
}

// Log reducer identical to incremental_stream.cc
static void log_result_recorder(
    const std::map<int, std::tuple<double, double, double, double>> &result_recorder,
    const std::map<int, std::tuple<float, float>> &comparison_recorder,
    const int amount, std::ofstream& out_file) {
    for (auto item : result_recorder) {
        const auto &[recall, calDistTime, internal_search_time, fetch_nn_time] = item.second;
        const auto &[comps, hops] = comparison_recorder.at(item.first);
        const auto cur_range_amount = amount / result_recorder.size();
        out_file << std::setiosflags(std::ios::fixed) << std::setprecision(4)
             << "range: " << item.first
             << "\t recall: " << recall / cur_range_amount
             << "\t QPS: " << std::setprecision(0)
             << cur_range_amount / internal_search_time << "\t"
             << "Comps: " << comps / cur_range_amount << std::setprecision(4)
             << "\t Hops: " << hops / cur_range_amount << std::setprecision(4) << std::endl;
    }
}

// Flatten a subset of nodes (by original ids) into a contiguous float* buffer
static float* flatten_subset(const vector<vector<float>> &nodes, const vector<unsigned> &ids, int dim) {
    float *buf = new float[(size_t)ids.size() * (size_t)dim];
    for (size_t i = 0; i < ids.size(); i++) {
        const auto &row = nodes[ids[i]];
        std::memcpy(buf + i * dim, row.data(), sizeof(float) * (size_t)dim);
    }
    return buf;
}

int main(int argc, char **argv) {
    // Parameters (defaults mirror incremental_stream.cc where applicable)
    int data_size = 1000000; // may be overridden by -N
    int part_num = 10;
    unsigned index_k = 16; // used as DIGRA's M
    unsigned ef_max = 500;
    unsigned ef_construction = 100;
    float alpha = 1.0f; // unused in DIGRA
    int query_num = 1000;
    int query_k = 10;

    string dataset = "deep";
    string dataset_path = "";
    string query_path = "";

    for (int i = 0; i < argc; i++) {
        string arg = argv[i];
        if (arg == "-dataset") dataset = string(argv[i + 1]);
        if (arg == "-dataset_path") dataset_path = string(argv[i + 1]);
        if (arg == "-query_path") query_path = string(argv[i + 1]);
        if (arg == "-k") index_k = (unsigned)atoi(argv[i + 1]);
        if (arg == "-ef_max") ef_max = (unsigned)atoi(argv[i + 1]);
        if (arg == "-ef_construction") ef_construction = (unsigned)atoi(argv[i + 1]);
        if (arg == "-alpha") alpha = (float)atof(argv[i + 1]);
        if (arg == "-N") data_size = atoi(argv[i + 1]);
    }

    string root_path = "/research/projects/zp128/RangeIndexWithRandomInsertion";
    string gt_dir = "/groundtruth/incremental/wiki-image_1m-num1000-k10/groundtruth_part_";
    string permutation_path = root_path + "/groundtruth/incremental/wiki-image_1m-num1000-k10/permutation.bin";
    vector<string> gt_paths;
    for (int i = 0; i < part_num; i++) {
        gt_paths.emplace_back(root_path + gt_dir + to_string(i) + ".csv");
    }
    if (dataset != "wiki-image") {
        ReplaceSubstringInPaths(gt_paths, "wiki-image", dataset);
        ReplaceSubstringInPath(permutation_path, "wiki-image", dataset);
    }

    cout << "Print the first groundtruth path" << gt_paths[0] << endl;

    auto insert_batches = ReadAndSplit(permutation_path, part_num);
    DataWrapper data_wrapper(query_num, query_k, dataset, data_size);
    data_wrapper.readData(dataset_path, query_path);

    // Build DIGRA index incrementally, aligning key/value to positional ids
    const int dim = (int)data_wrapper.data_dim;
    // Prepare search ef sweep values
    int st = 16, ed = 64, stride = 4;
    std::vector<int> searchef_para_range_list;
    for (int i = 6; i < st; i += 1) searchef_para_range_list.push_back(i);
    for (int i = st; i <= ed; i += stride) searchef_para_range_list.push_back(i);
    for (int i = ed + stride; i <= 128; i += 16) searchef_para_range_list.push_back(i);
    cout << "search ef:" << endl;
    print_set(searchef_para_range_list);

    // Initialize DIGRA with the first batch
    const auto &first_batch = insert_batches[0];
    vector<unsigned> init_ids = first_batch; // copy
    float *baseData = flatten_subset(data_wrapper.nodes, init_ids, dim);
    int *keyList = new int[(size_t)data_size];
    int *valueList = new int[(size_t)data_size];
    for (size_t i = 0; i < init_ids.size(); i++) {
        keyList[i] = (int)init_ids[i];
        valueList[i] = (int)init_ids[i];
    }

    RangeHNSW rangeHnsw(dim, init_ids.size(), (size_t)data_size, baseData, keyList, valueList, (int)index_k, (int)ef_construction);

    // Evaluate part 0 then insert subsequent batches and evaluate each part
    for (int i = 0; i < part_num; i++) {
        // Measure and report the insertion time for each incremental batch (i > 0)
        double batch_insert_seconds = 0.0;
        size_t batch_insert_count = 0;
        if (i > 0) {
            const auto &batch = insert_batches[i];
            auto t_insert_start = std::chrono::high_resolution_clock::now();
            for (unsigned id : batch) {
                rangeHnsw.addPoint((int)id, (int)id, (char*)data_wrapper.nodes[id].data());
            }
            auto t_insert_end = std::chrono::high_resolution_clock::now();
            batch_insert_seconds = std::chrono::duration<double>(t_insert_end - t_insert_start).count();
            batch_insert_count = batch.size();
            const double batch_insert_ips = batch_insert_seconds > 0.0 ? (double)batch_insert_count / batch_insert_seconds : 0.0;
            cout << std::setiosflags(std::ios::fixed) << std::setprecision(4)
                 << "Batch " << i << " insertion: " << batch_insert_count
                 << " points in " << batch_insert_seconds << " s"
                 << ", IPS: " << batch_insert_ips << endl;
        }

        data_wrapper.LoadGroundtruth(gt_paths[i]);

        std::map<int, std::tuple<double, double, double, double>> result_recorder; // recall, calDist, internal_search, fetch_nn
        std::map<int, std::tuple<float, float>> comparison_recorder; // comps, hops (DIGRA does not expose, keep zeros)

        cout << "Evaluating part " << i << endl;
        std::ofstream logfile;
        string log_dir = root_path + "/log/incremental_stream/digra/" + dataset + "/";
        struct stat st = {};
        if (stat(log_dir.c_str(), &st) != 0) {
            mkdir(log_dir.c_str(), 0777);
        }
        string log_path = log_dir + "part_" + to_string(i) + ".log";
        logfile.open(log_path);
        if (i > 0) {
            const double batch_insert_ips = batch_insert_seconds > 0.0 ? (double)batch_insert_count / batch_insert_seconds : 0.0;
            logfile << std::setiosflags(std::ios::fixed) << std::setprecision(4)
                    << "Batch " << i << " insertion: " << batch_insert_count
                    << " points, " << batch_insert_seconds << " s"
                    << ", IPS: " << batch_insert_ips << std::endl;
        }

        for (auto one_searchef : searchef_para_range_list) {
            // Reset accumulators
            result_recorder.clear();
            comparison_recorder.clear();

            for (int idx = 0; idx < (int)data_wrapper.query_ids.size(); idx++) {
                int one_id = data_wrapper.query_ids.at(idx);
                auto ql = data_wrapper.query_ranges.at(idx).first;
                auto qr = data_wrapper.query_ranges.at(idx).second;
                int query_range = qr - ql + 1;

                auto t1 = std::chrono::high_resolution_clock::now();
                auto pq = rangeHnsw.queryRange((float*)data_wrapper.querys.at(one_id).data(), ql, qr, data_wrapper.query_k, one_searchef);
                auto t2 = std::chrono::high_resolution_clock::now();
                double elapsed = std::chrono::duration<double>(t2 - t1).count();
                vector<int> res;
                while (!pq.empty()) { res.push_back((int)pq.top().second); pq.pop(); }

                double prec = countPrecision(data_wrapper.groundtruth.at(idx), res);
                std::get<0>(result_recorder[query_range]) += prec;
                // Accumulate actual internal (query) time in seconds to enable correct QPS
                std::get<2>(result_recorder[query_range]) += elapsed;
                std::get<1>(result_recorder[query_range]) += 0.0;
                std::get<3>(result_recorder[query_range]) += 0.0;
                std::get<0>(comparison_recorder[query_range]) += 0.0f;
                std::get<1>(comparison_recorder[query_range]) += 0.0f;
            }

            logfile << std::endl
                    << "Search ef: " << one_searchef << std::endl
                    << "========================" << std::endl;
            log_result_recorder(result_recorder, comparison_recorder, (int)data_wrapper.query_ids.size(), logfile);
            logfile << "========================" << std::endl;
        }
        logfile.close();
    }

    delete[] baseData;
    delete[] keyList;
    delete[] valueList;
    return 0;
}


